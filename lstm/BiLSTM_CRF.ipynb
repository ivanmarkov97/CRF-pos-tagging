{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM-CRF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4852oR-ijn-"
      },
      "source": [
        "!pip install --quiet pytorch-crf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecO9YPrGkgVI"
      },
      "source": [
        "import os\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import functools\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "\r\n",
        "from torchtext import datasets\r\n",
        "from torchtext.data import Field\r\n",
        "from torchtext.data import BucketIterator\r\n",
        "\r\n",
        "from torchcrf import CRF\r\n",
        "\r\n",
        "\r\n",
        "SEED = 241"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEDmDBuhkFlY"
      },
      "source": [
        "def seed_everything(seed):\r\n",
        "  random.seed(seed)\r\n",
        "  np.random.seed(seed)\r\n",
        "  torch.manual_seed(seed)\r\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
        "\r\n",
        "  if torch.cuda.is_available(): \r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed_all(seed)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "    torch.backends.cudnn.benchmark = True\r\n",
        "\r\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPpRja0nk8Cd"
      },
      "source": [
        "TEXT = Field(lower=True,\r\n",
        "             use_vocab=True,\r\n",
        "             sequential=True,\r\n",
        "             batch_first=True,\r\n",
        "             include_lengths=True)\r\n",
        "\r\n",
        "LABEL = Field(lower=True,\r\n",
        "              use_vocab=True,\r\n",
        "              sequential=True,\r\n",
        "              unk_token = None,\r\n",
        "              batch_first=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h2zGNigmB4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786e8cd0-daf6-405a-ffad-7373d4f4e7e2"
      },
      "source": [
        "fields = [('text', TEXT), ('tags', LABEL)]\r\n",
        "\r\n",
        "train_data, valid_data, test_data = datasets.UDPOS.splits(fields)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading en-ud-v2.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "en-ud-v2.zip: 100%|██████████| 688k/688k [00:00<00:00, 1.69MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Cnp-ZNsm4LF",
        "outputId": "15736649-a9c3-4b11-9b88-a46898cd56c5"
      },
      "source": [
        "TEXT.build_vocab(train_data,\r\n",
        "                 max_size=25000,\r\n",
        "                 vectors='glove.6B.100d')\r\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                          \n",
            "100%|█████████▉| 398718/400000 [00:23<00:00, 17168.85it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_7Qb54WqZ12"
      },
      "source": [
        "batch_size = 32\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "# device = torch.device('cpu')\r\n",
        "\r\n",
        "\r\n",
        "train_iterator = BucketIterator.splits((train_data,), batch_size=batch_size, device=device)[0]\r\n",
        "valid_iterator = BucketIterator.splits((valid_data,), batch_size=batch_size, device=device)[0]\r\n",
        "test_iterator = BucketIterator.splits((test_data,), batch_size=batch_size, device=device)[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJXy40T8vWfp"
      },
      "source": [
        "class BiLSTM_CRF_Tagger(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, vocab_size, emb_size, hidden_size, n_layers, dropout, num_tags, pad_idx, device):\r\n",
        "    super().__init__()\r\n",
        "    self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=pad_idx)\r\n",
        "    self.rnn = nn.LSTM(emb_size,\r\n",
        "                       hidden_size, \r\n",
        "                       num_layers=n_layers,\r\n",
        "                       dropout=0.3, \r\n",
        "                       bidirectional=True, \r\n",
        "                       batch_first=True)\r\n",
        "    \r\n",
        "    self.dropout = nn.Dropout(dropout)\r\n",
        "    self.hidden2tag = nn.Linear(emb_size, num_tags)\r\n",
        "    self.crf = CRF(num_tags, batch_first=True)\r\n",
        "    self.device = device\r\n",
        "\r\n",
        "  def _generate_mask(self, text_lens):\r\n",
        "    bs = text_lens.size(0)\r\n",
        "    max_seq_len = torch.max(text_lens).item()\r\n",
        "    mask = torch.ByteTensor(bs, max_seq_len).fill_(0)\r\n",
        "    for i in range(bs):\r\n",
        "      mask[i, :text_lens[i]] = 1\r\n",
        "    return mask\r\n",
        "\r\n",
        "  def forward(self, text, text_lens, tags=None):\r\n",
        "    text_embed = self.embedding(text)\r\n",
        "\r\n",
        "    text_packed = nn.utils.rnn.pack_padded_sequence(text_embed, text_lens, batch_first=True, enforce_sorted=False)\r\n",
        "    rnn_outputs, (last_hidden, cell_state) = self.rnn(text_packed)\r\n",
        "    text_unpacked, lens_unpacked = nn.utils.rnn.pad_packed_sequence(text_packed, batch_first=True)\r\n",
        "    last_hidden = last_hidden.permute(1, 0, 2)\r\n",
        "\r\n",
        "    emission = self.hidden2tag(text_unpacked)\r\n",
        "    mask = self._generate_mask(text_lens).to(self.device)\r\n",
        "\r\n",
        "    if tags is not None:\r\n",
        "      loss = -self.crf.forward(torch.log_softmax(emission, dim=2), tags, mask, reduction='mean')\r\n",
        "      return loss\r\n",
        "    else:\r\n",
        "      prediction = self.crf.decode(emission, mask)\r\n",
        "      return prediction"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f-UjvbozoF5"
      },
      "source": [
        "VOCAB_SIZE = len(TEXT.vocab)\r\n",
        "EMB_SIZE = 100\r\n",
        "HIDDEN_SIZE = 128\r\n",
        "N_LAYERS = 2\r\n",
        "DROPOUT = 0.3\r\n",
        "NUM_TAGS = len(LABEL.vocab)\r\n",
        "PAD_IDX = LABEL.vocab.stoi['<pad>']\r\n",
        "\r\n",
        "\r\n",
        "model = BiLSTM_CRF_Tagger(VOCAB_SIZE, EMB_SIZE, HIDDEN_SIZE, N_LAYERS, DROPOUT, NUM_TAGS, PAD_IDX, device)\r\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gvS8CZjAliW",
        "outputId": "af0bf7fa-d418-4bf4-88e8-18d8133293ae"
      },
      "source": [
        "model.embedding.weight.data.copy_(TEXT.vocab.vectors)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.2634,  0.0742, -0.1081,  ..., -0.2977, -0.5655,  0.5218],\n",
              "        [ 0.4244,  0.6004, -0.1528,  ...,  0.2536, -0.4969,  0.8964]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke0M2LQqFLFc"
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-AAJvc4R49-"
      },
      "source": [
        "def train_epoch(model, iterator, optimizer):\r\n",
        "  model.train()\r\n",
        "  error = 0.\r\n",
        "\r\n",
        "  for batch in iterator:\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    text, lens = batch.text\r\n",
        "    lens = lens.cpu()\r\n",
        "    tags = batch.tags\r\n",
        "    \r\n",
        "    loss = model(text, lens, tags)\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "    error += loss.detach().cpu().numpy()\r\n",
        "  return error / len(iterator)\r\n",
        "\r\n",
        "def valid_epoch(model, iterator):\r\n",
        "  error = 0.\r\n",
        "  model.eval()\r\n",
        "  with torch.no_grad():\r\n",
        "    for batch in iterator:\r\n",
        "      text, lens = batch.text\r\n",
        "      lens = lens.cpu()\r\n",
        "      tags = batch.tags\r\n",
        "      \r\n",
        "      loss = model(text, lens, tags)\r\n",
        "      error += loss.detach().cpu().numpy()\r\n",
        "  return error / len(iterator)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJlBxyc6W9Ds"
      },
      "source": [
        "from sklearn.metrics import f1_score\r\n",
        "\r\n",
        "\r\n",
        "def calculate_accuracy(y_true, y_pred):\r\n",
        "  assert y_true.shape == y_pred.shape\r\n",
        "  assert len(y_true.shape) == 1\r\n",
        "  y_true = y_true[1:]\r\n",
        "  y_pred = y_pred[1:]\r\n",
        "  return (y_true == y_pred).sum() / y_true.shape[0]\r\n",
        "\r\n",
        "\r\n",
        "def calculate_metrics(model, dataset, device):\r\n",
        "\r\n",
        "  total_true_labels = []\r\n",
        "  total_pred_labels = []\r\n",
        "\r\n",
        "  for index in range(len(dataset.examples)):\r\n",
        "\r\n",
        "    text = dataset.examples[index].text\r\n",
        "    true_labels = dataset.examples[index].tags\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      tokens = text\r\n",
        "      ids = [TEXT.vocab.stoi[token] for token in tokens]\r\n",
        "      ids_tensor = torch.tensor([ids], device=device)\r\n",
        "      lens = torch.tensor([len(ids)])\r\n",
        "      prediction = model(ids_tensor, lens)\r\n",
        "      \r\n",
        "    # print('\\t'.join(tokens))\r\n",
        "    # print('\\t'.join(true_labels))\r\n",
        "    # print('\\t'.join([LABEL.vocab.itos[p] for p in prediction[0]]))\r\n",
        "    # print('='*20)\r\n",
        "\r\n",
        "    total_true_labels.extend(np.array([LABEL.vocab.itos[p] for p in prediction[0]]))\r\n",
        "    total_pred_labels.extend(np.array(true_labels))\r\n",
        "\r\n",
        "  accurary = calculate_accuracy(np.array(total_true_labels), np.array(total_pred_labels))\r\n",
        "  f1 = f1_score(np.array(total_true_labels), np.array(total_pred_labels), average='macro')\r\n",
        "  print(f'Accuracy: {accurary}, F1: {f1}')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW1yKkgSsOi-",
        "outputId": "87f2bdd7-a4d0-49fe-d789-3c64aea80400"
      },
      "source": [
        "for epoch in range(10):\r\n",
        "  train_error = train_epoch(model, train_iterator, optimizer)\r\n",
        "  valid_error = valid_epoch(model, valid_iterator)\r\n",
        "\r\n",
        "  print(f'Epoch: {epoch + 1}. Train: {train_error}, Valid: {valid_error}')\r\n",
        "  calculate_metrics(model, test_data, device)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1. Train: 17.42588615904049, Valid: 7.180066464439271\n",
            "Accuracy: 0.8614121772394007, F1: 0.765385346021073\n",
            "Epoch: 2. Train: 6.21093812584877, Valid: 5.283478176783001\n",
            "Accuracy: 0.8879502709595155, F1: 0.8115996025956886\n",
            "Epoch: 3. Train: 4.365908656193286, Valid: 4.647811416595701\n",
            "Accuracy: 0.8938077781319732, F1: 0.8205040273897427\n",
            "Epoch: 4. Train: 3.541363316531084, Valid: 4.360866300643436\n",
            "Accuracy: 0.8950430347465732, F1: 0.8212128244621087\n",
            "Epoch: 5. Train: 3.0667514886174883, Valid: 4.166554924041506\n",
            "Accuracy: 0.8977526299011794, F1: 0.8262088919408904\n",
            "Epoch: 6. Train: 2.76078952149469, Valid: 4.057935169764927\n",
            "Accuracy: 0.9002629901179471, F1: 0.8311796484604893\n",
            "Epoch: 7. Train: 2.551663661185576, Valid: 4.009524122117058\n",
            "Accuracy: 0.900581766018489, F1: 0.8435991671541149\n",
            "Epoch: 8. Train: 2.408608538459758, Valid: 3.9787014533603\n",
            "Accuracy: 0.9014185527574116, F1: 0.8468406985481658\n",
            "Epoch: 9. Train: 2.304506330465784, Valid: 3.966500918070475\n",
            "Accuracy: 0.9020162575709276, F1: 0.8470214993205484\n",
            "Epoch: 10. Train: 2.231114434800586, Valid: 3.9528812983679393\n",
            "Accuracy: 0.9030522792476888, F1: 0.8499894059360147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2k0z1srKfYg"
      },
      "source": [
        "# from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "\r\n",
        "# print(classification_report(np.array(total_true_labels), np.array(total_pred_labels)))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwbTZBBzpxfn"
      },
      "source": [
        "## Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z57iAAUhK82z"
      },
      "source": [
        "# import torch.nn.utils.prune as prune\r\n",
        "\r\n",
        "\r\n",
        "# classifier = model.hidden2tag\r\n",
        "\r\n",
        "# for name, param in classifier.named_parameters():\r\n",
        "#   print(name, param)\r\n",
        "\r\n",
        "# prune.random_unstructured(classifier, name='weight', amount=0.3)\r\n",
        "# prune.l1_unstructured(classifier, name=\"bias\", amount=3)\r\n",
        "\r\n",
        "# for name, param in classifier.named_parameters():\r\n",
        "#   print(name, param)\r\n",
        "\r\n",
        "# print(list(classifier.named_buffers()))\r\n",
        "# print(classifier.weight)\r\n",
        "# print(classifier._forward_pre_hooks)\r\n",
        "\r\n",
        "# prune.remove(classifier, 'weight')\r\n",
        "# prune.remove(classifier, 'bias')\r\n",
        "\r\n",
        "# print(torch.sum(model.hidden2tag.weight == 0) / model.hidden2tag.weight.nelement() * 100)\r\n",
        "# print(calculate_metrics(model, test_data))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiS7rXalj3Bk"
      },
      "source": [
        "# for epoch in range(2):\r\n",
        "#   train_error = train_epoch(model, train_iterator, optimizer)\r\n",
        "#   valid_error = valid_epoch(model, valid_iterator)\r\n",
        "\r\n",
        "#   print(f'Epoch: {epoch + 1}. Train: {train_error}, Valid: {valid_error}')\r\n",
        "#   calculate_metrics(model, test_data)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prTWafGWx1AO"
      },
      "source": [
        "## Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PN81wCqRY0K"
      },
      "source": [
        "model = model.cpu()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVNIXOizx2kw",
        "outputId": "d4711177-ab63-43c4-f9c2-967adb8b98c9"
      },
      "source": [
        "from torch.quantization import quantize_dynamic\r\n",
        "\r\n",
        "\r\n",
        "quantized_model = torch.quantization.quantize_dynamic(\r\n",
        "    model, {nn.LSTM, nn.Linear}, dtype=torch.qint8\r\n",
        ")\r\n",
        "\r\n",
        "print(quantized_model)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BiLSTM_CRF_Tagger(\n",
            "  (embedding): Embedding(16655, 100, padding_idx=0)\n",
            "  (rnn): DynamicQuantizedLSTM(100, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (hidden2tag): DynamicQuantizedLinear(in_features=100, out_features=18, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
            "  (crf): CRF(num_tags=18)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEcPLz3wRbzp",
        "outputId": "45d04d78-ae79-4f4f-e253-1344a5560190"
      },
      "source": [
        "def print_size_of_model(model):\r\n",
        "    torch.save(model.state_dict(), \"temp.p\")\r\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\r\n",
        "    os.remove('temp.p')\r\n",
        "\r\n",
        "print_size_of_model(model)\r\n",
        "print_size_of_model(quantized_model)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size (MB): 9.200664\n",
            "Size (MB): 7.317217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50Zl_m6KRs6w"
      },
      "source": [
        "model = model.to(device)\r\n",
        "quantized_model = quantized_model.to(device)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYoqfC4KV2zp",
        "outputId": "ef267d21-7bc9-40e7-bd55-8e69eece2b9b"
      },
      "source": [
        "cpu_device = torch.device('cpu')\r\n",
        "quantized_model.device = cpu_device\r\n",
        "quantized_model.to(cpu_device)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTM_CRF_Tagger(\n",
              "  (embedding): Embedding(16655, 100, padding_idx=0)\n",
              "  (rnn): DynamicQuantizedLSTM(100, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (hidden2tag): DynamicQuantizedLinear(in_features=100, out_features=18, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
              "  (crf): CRF(num_tags=18)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfnHIQiPRi9D",
        "outputId": "56f2c6cf-ba8c-439a-8c82-3cebe1bffb57"
      },
      "source": [
        "print(calculate_metrics(model, test_data, device))\r\n",
        "print(calculate_metrics(quantized_model, test_data, cpu_device))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9030522792476888, F1: 0.8499894059360147\n",
            "None\n",
            "Accuracy: 0.9024944214217405, F1: 0.8494212786231817\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUUN51oiRr2t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}